2025-05-31 23:41:36,398 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.16.20.6:33865'
2025-05-31 23:41:37,223 - distributed.worker - INFO -       Start worker at:    tcp://172.16.20.6:37613
2025-05-31 23:41:37,223 - distributed.worker - INFO -          Listening to:    tcp://172.16.20.6:37613
2025-05-31 23:41:37,223 - distributed.worker - INFO -          dashboard at:          172.16.20.6:46453
2025-05-31 23:41:37,223 - distributed.worker - INFO - Waiting to connect to:    tcp://172.16.20.28:8786
2025-05-31 23:41:37,223 - distributed.worker - INFO - -------------------------------------------------
2025-05-31 23:41:37,223 - distributed.worker - INFO -               Threads:                          1
2025-05-31 23:41:37,223 - distributed.worker - INFO -                Memory:                  14.90 GiB
2025-05-31 23:41:37,223 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vuicz6dj
2025-05-31 23:41:37,223 - distributed.worker - INFO - -------------------------------------------------
2025-05-31 23:41:38,626 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-05-31 23:41:38,626 - distributed.worker - INFO -         Registered to:    tcp://172.16.20.28:8786
2025-05-31 23:41:38,627 - distributed.worker - INFO - -------------------------------------------------
2025-05-31 23:41:38,627 - distributed.core - INFO - Starting established connection to tcp://172.16.20.28:8786
2025-06-01 02:03:38,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-06-01 02:03:41,343 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 12.23 GiB -- Worker memory limit: 14.90 GiB
2025-06-01 02:03:49,563 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 11.60 GiB -- Worker memory limit: 14.90 GiB
2025-06-01 02:05:43,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-06-01 02:06:00,123 - distributed.worker - INFO - Run out-of-band function 'lambda'
2025-06-01 02:06:00,137 - distributed.worker - INFO - Run out-of-band function 'lambda'
